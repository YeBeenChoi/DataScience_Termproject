# ðŸ›Œ Sleep Efficiency Classification & Regression

This project analyzes sleep health data to **predict and classify sleep efficiency**, using machine learning techniques. It includes full preprocessing, feature engineering, model training, evaluation, and hyperparameter tuning.

---

## ðŸ“Š Project Objectives

- **Regression**: Predict the actual sleep efficiency score (continuous value)
- **Classification**: Classify whether a person's sleep efficiency is **"sufficient" (â‰¥ 0.85)** or **"insufficient" (< 0.85)**

---

## ðŸ§¹ Preprocessing Steps

All preprocessing is implemented in `src/preprocess.py`.

- **Time Feature Engineering**  
  - `Bedtime`, `Wakeup time` â†’ Extract `hour` features
- **Multicollinearity Removal**  
  - Remove `Sleep duration` and `Deep sleep percentage`
- **Binary Encoding**  
  - Encode categorical variables: `Gender`, `Smoking status`
- **Outlier Elimination**  
  - Remove outliers in `Caffeine consumption` using IQR
- **Missing Value Imputation**  
  - Fill missing values using **median (numeric)** or **mode (categorical)**, stratified by `Gender`
- **Optional Feature Drop**  
  - Remove `REM sleep percentage`, `Light sleep percentage` when specified

---

## âš™ï¸ Model Overview

### ðŸ”  Classification

- **Target**: Sleep_Label (1 if efficiency â‰¥ 0.85, else 0)
- **Models Used**:
  - Logistic Regression
  - Decision Tree Classifier
  - Random Forest Classifier
- **Evaluation Metrics**:
  - Accuracy
  - Mean Squared Error (MSE)
  - RÂ² Score
- **Validation**:
  - Stratified K-Fold Cross Validation (k = 3, 5, 10)
- **Tuning**:
  - Performed using `GridSearchCV` and `RandomizedSearchCV` (Random Forest)

ðŸ“Œ **Best Model**:  
âœ… Random Forest (RandomSearch, 5-Fold)

---

### ðŸ“ˆ Regression

- **Target**: Sleep efficiency (float)
- **Models Used**:
  - Linear Regression
  - Random Forest Regressor
  - Gradient Boosting Regressor
- **Evaluation Metrics**:
  - RÂ² Score
  - Mean Squared Error (MSE)
- **Validation**:
  - K-Fold Cross Validation (k = 3, 5, 10)
- **Tuning**:
  - Random Forest tuned via `GridSearchCV` and `RandomizedSearchCV`

ðŸ“Œ **Best Model**:  
âœ… Random Forest Regressor (RandomSearch, 5-Fold)

---

## âš–ï¸ Scaler Comparison

To evaluate the effect of feature scaling, we compared:

- `StandardScaler`
- `MinMaxScaler`
- `RobustScaler`

**Result:**  
All three scalers produced similar results.  
âž¡ï¸ `StandardScaler` was chosen for final use due to simplicity and interpretability.

---

## ðŸ“ Repository Structure

```
datascience-termproject/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ main.ipynb          # Kaggle notebook with full analysis
â”œâ”€â”€ src/
â”‚   â””â”€â”€ preprocess.py       # Preprocessing function
â”œâ”€â”€ LICENSE                 # Apache License 2.0
â”œâ”€â”€ README.md               # This file
â”œâ”€â”€ requirements.txt        # Required packages
â””â”€â”€ .gitignore              # Files to ignore in Git
```

---

## ðŸ› ï¸ How to Run

1. Clone this repository:

   ```bash
   git clone https://github.com/yourusername/datascience-termproject.git
   cd datascience-termproject
   ```

2. Install required packages:

   ```bash
   pip install -r requirements.txt
   ```

3. Run the notebook:

   - Open `notebooks/main.ipynb` in Jupyter Notebook or VS Code
   - Execute each cell step by step

4. (Optional) Use `src/preprocess.py` as a reusable preprocessing module for new datasets

---

## ðŸ“œ License

This project is licensed under the **Apache License 2.0**.  
You are free to use, modify, and distribute this code for commercial and non-commercial purposes.  
Just include the LICENSE file and indicate any changes you made.

See the [LICENSE](./LICENSE) file for full license text.

