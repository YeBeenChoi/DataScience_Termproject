{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed246a81",
   "metadata": {
    "papermill": {
     "duration": 0.002821,
     "end_time": "2025-06-02T06:35:35.833132",
     "exception": false,
     "start_time": "2025-06-02T06:35:35.830311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### If you do it at once, it'll take too long\n",
    "\n",
    "### Preprocessing\n",
    "- Time processing: Bedtime, Wakeup → hour, minute decomposition\n",
    "- Multicollinearity removal: Sleep duration, Deep sleep%\n",
    "- Binary encoding: Gender, smoking status\n",
    "- Eliminating outliers: Caffeine consumption (IQR)\n",
    "- Missing value processing: mean/median based on Gender\n",
    "- Add REM/Light Exclusion Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe4a3c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T06:35:35.840405Z",
     "iopub.status.busy": "2025-06-02T06:35:35.840032Z",
     "iopub.status.idle": "2025-06-02T06:35:37.929587Z",
     "shell.execute_reply": "2025-06-02T06:35:37.928624Z"
    },
    "papermill": {
     "duration": 2.094948,
     "end_time": "2025-06-02T06:35:37.931303",
     "exception": false,
     "start_time": "2025-06-02T06:35:35.836355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def preprocess(df, drop_sleep_features=True):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Time Variables → Decompose numerically\n",
    "    df[\"Bedtime\"] = pd.to_datetime(df[\"Bedtime\"])\n",
    "    df[\"Wakeup time\"] = pd.to_datetime(df[\"Wakeup time\"])\n",
    "    df[\"Bedtime_hour\"] = df[\"Bedtime\"].dt.hour\n",
    "    df[\"Wakeup_hour\"] = df[\"Wakeup time\"].dt.hour\n",
    "\n",
    "    # Remove multicollinearity (Sleep duration, Deep sleep%)\n",
    "    df.drop(columns=[\"Sleep duration\", \"Deep sleep percentage\", \"ID\", \"Bedtime\", \"Wakeup time\"], inplace=True, errors='ignore')\n",
    "\n",
    "    # categorical encoding\n",
    "    df[\"Gender\"] = df[\"Gender\"].map({\"Female\": 0, \"Male\": 1})\n",
    "    df[\"Smoking status\"] = df[\"Smoking status\"].map({\"No\": 0, \"Yes\": 1})\n",
    "\n",
    "    # Eliminating Outliers (Caffeine IQR)\n",
    "    Q1 = df[\"Caffeine consumption\"].quantile(0.25)\n",
    "    Q3 = df[\"Caffeine consumption\"].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df = df[(df[\"Caffeine consumption\"] >= Q1 - 1.5 * IQR) & \n",
    "            (df[\"Caffeine consumption\"] <= Q3 + 1.5 * IQR)]\n",
    "\n",
    "    # Missing value processing (median value based on gender)\n",
    "    df[\"Caffeine consumption\"] = df.groupby(\"Gender\")[\"Caffeine consumption\"].transform(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "    # Process other missing values as well\n",
    "    for col in df.columns:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            if df[col].dtype in [np.float64, np.int64]:\n",
    "                df[col] = df[col].fillna(df[col].median())\n",
    "            else:\n",
    "                df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "    # Remove as per REM/Light option\n",
    "    if drop_sleep_features:\n",
    "        df = df.drop(columns=[\"REM sleep percentage\", \"Light sleep percentage\"], errors='ignore')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bb6583",
   "metadata": {
    "papermill": {
     "duration": 0.00256,
     "end_time": "2025-06-02T06:35:37.936525",
     "exception": false,
     "start_time": "2025-06-02T06:35:37.933965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Experiment with StandardScaler, MinMaxScaler, and RobustScaler respectively and select the scaler that performs best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5133bef4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T06:35:37.943251Z",
     "iopub.status.busy": "2025-06-02T06:35:37.942584Z",
     "iopub.status.idle": "2025-06-02T06:35:42.661048Z",
     "shell.execute_reply": "2025-06-02T06:35:42.659081Z"
    },
    "papermill": {
     "duration": 4.7244,
     "end_time": "2025-06-02T06:35:42.663137",
     "exception": false,
     "start_time": "2025-06-02T06:35:37.938737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Regression (Linear Regression) ===\n",
      "\n",
      "StandardScaler:\n",
      "  Mean RMSE: 0.0618 ± 0.0058\n",
      "  Mean R²:   0.7826 ± 0.0562\n",
      "\n",
      "MinMaxScaler:\n",
      "  Mean RMSE: 0.0618 ± 0.0058\n",
      "  Mean R²:   0.7826 ± 0.0562\n",
      "\n",
      "RobustScaler:\n",
      "  Mean RMSE: 0.0618 ± 0.0058\n",
      "  Mean R²:   0.7826 ± 0.0562\n",
      "\n",
      "=== Classification (Random Forest) ===\n",
      "\n",
      "StandardScaler:\n",
      "  Mean Accuracy: 0.9286 ± 0.0149\n",
      "\n",
      "MinMaxScaler:\n",
      "  Mean Accuracy: 0.9264 ± 0.0164\n",
      "\n",
      "RobustScaler:\n",
      "  Mean Accuracy: 0.9242 ± 0.0189\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "\n",
    "# Import data\n",
    "df = pd.read_csv(\"/kaggle/input/sleep-efficiency/Sleep_Efficiency_preprocessed.csv\")\n",
    "X = df.drop('Sleep efficiency', axis=1)\n",
    "y_reg = df['Sleep efficiency']\n",
    "\n",
    "y_cls = (y_reg >= 0.85).astype(int)\n",
    "\n",
    "# Define the scaler to compare\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler()\n",
    "}\n",
    "\n",
    "# Comparison of regression model performance\n",
    "print('=== Regression (Linear Regression) ===')\n",
    "for name, scaler in scalers.items():\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', scaler),\n",
    "        ('model', LinearRegression())\n",
    "    ])\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    # neg_root_mean_squared_error는 음수로 반환되므로 부호를 바꿔 RMSE 구함\n",
    "    rmse = -cross_val_score(pipe, X, y_reg, cv=kf, scoring='neg_root_mean_squared_error')\n",
    "    r2  =  cross_val_score(pipe, X, y_reg, cv=kf, scoring='r2')\n",
    "    print(f'\\n{name}:')\n",
    "    print(f'  Mean RMSE: {rmse.mean():.4f} ± {rmse.std():.4f}')\n",
    "    print(f'  Mean R²:   {r2.mean():.4f} ± {r2.std():.4f}')\n",
    "\n",
    "# Classification Model Performance Comparison\n",
    "print('\\n=== Classification (Random Forest) ===')\n",
    "for name, scaler in scalers.items():\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', scaler),\n",
    "        ('model', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    acc = cross_val_score(pipe, X, y_cls, cv=skf, scoring='accuracy')\n",
    "    print(f'\\n{name}:')\n",
    "    print(f'  Mean Accuracy: {acc.mean():.4f} ± {acc.std():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9bba5d",
   "metadata": {
    "papermill": {
     "duration": 0.002115,
     "end_time": "2025-06-02T06:35:42.668575",
     "exception": false,
     "start_time": "2025-06-02T06:35:42.666460",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Select StandardScaler because all three scalers have the same results for regression models and are almost the same for classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cf7c01",
   "metadata": {
    "papermill": {
     "duration": 0.002018,
     "end_time": "2025-06-02T06:35:42.672759",
     "exception": false,
     "start_time": "2025-06-02T06:35:42.670741",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Classification\n",
    "- Criteria: Sleep efficiency ≥ 0.85 → 1, less than → 0\n",
    "- Model: LogisticRegression, DecisionTree, RandomForest\n",
    "- Evaluation: Accuracy, MSE, R² (StratifiedKFold)\n",
    "- Choose the best model among the three models and tune it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6715797d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T06:35:42.678523Z",
     "iopub.status.busy": "2025-06-02T06:35:42.678198Z",
     "iopub.status.idle": "2025-06-02T06:36:16.604998Z",
     "shell.execute_reply": "2025-06-02T06:36:16.603768Z"
    },
    "papermill": {
     "duration": 33.932404,
     "end_time": "2025-06-02T06:36:16.607174",
     "exception": false,
     "start_time": "2025-06-02T06:35:42.674770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      KFold                                  Model Stage  Accuracy       MSE  \\\n",
      "0      Test                    Logistic Regression  Test  0.920455  0.065009   \n",
      "1    3-Fold                    Logistic Regression    CV  0.908571  0.072590   \n",
      "2    5-Fold                    Logistic Regression    CV  0.905714  0.068050   \n",
      "3   10-Fold                    Logistic Regression    CV  0.902857  0.070470   \n",
      "4      Test                          Decision Tree  Test  0.943182  0.056818   \n",
      "5    3-Fold                          Decision Tree    CV  0.885714  0.114286   \n",
      "6    5-Fold                          Decision Tree    CV  0.880000  0.120000   \n",
      "7   10-Fold                          Decision Tree    CV  0.882857  0.117143   \n",
      "8      Test                          Random Forest  Test  0.943182  0.047052   \n",
      "9    3-Fold                          Random Forest    CV  0.911429  0.075722   \n",
      "10   5-Fold                          Random Forest    CV  0.922857  0.069908   \n",
      "11  10-Fold                          Random Forest    CV  0.922857  0.068953   \n",
      "12     Test     Random Forest (GridSearch, 3-Fold)  Test  0.954545  0.054286   \n",
      "13   3-Fold     Random Forest (GridSearch, 3-Fold)    CV  0.914286  0.080411   \n",
      "14     Test   Random Forest (RandomSearch, 3-Fold)  Test  0.943182  0.051490   \n",
      "15   3-Fold   Random Forest (RandomSearch, 3-Fold)    CV  0.917143  0.079861   \n",
      "16     Test     Random Forest (GridSearch, 5-Fold)  Test  0.931818  0.044822   \n",
      "17   5-Fold     Random Forest (GridSearch, 5-Fold)    CV  0.931429  0.068702   \n",
      "18     Test   Random Forest (RandomSearch, 5-Fold)  Test  0.943182  0.047623   \n",
      "19   5-Fold   Random Forest (RandomSearch, 5-Fold)    CV  0.931429  0.069831   \n",
      "20     Test    Random Forest (GridSearch, 10-Fold)  Test  0.943182  0.048499   \n",
      "21  10-Fold    Random Forest (GridSearch, 10-Fold)    CV  0.928571  0.069265   \n",
      "22     Test  Random Forest (RandomSearch, 10-Fold)  Test  0.954545  0.049745   \n",
      "23  10-Fold  Random Forest (RandomSearch, 10-Fold)    CV  0.928571  0.073053   \n",
      "\n",
      "          R²  \n",
      "0   0.739963  \n",
      "1   0.705399  \n",
      "2   0.723825  \n",
      "3   0.714001  \n",
      "4   0.772727  \n",
      "5   0.536178  \n",
      "6   0.512987  \n",
      "7   0.524583  \n",
      "8   0.811791  \n",
      "9   0.692686  \n",
      "10  0.716281  \n",
      "11  0.720157  \n",
      "12  0.782855  \n",
      "13  0.673656  \n",
      "14  0.794040  \n",
      "15  0.675887  \n",
      "16  0.820711  \n",
      "17  0.721178  \n",
      "18  0.809506  \n",
      "19  0.716594  \n",
      "20  0.806004  \n",
      "21  0.718891  \n",
      "22  0.801019  \n",
      "23  0.703521  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score, confusion_matrix\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Data loading and label creation\n",
    "df = pd.read_csv(\"/kaggle/input/sleep-efficiency/ModelingSet.csv\")\n",
    "df['Sleep_Label'] = (df['Sleep efficiency'] >= 0.85).astype(int)\n",
    "\n",
    "# Feature settings\n",
    "X = df.drop(columns=['Sleep efficiency', 'Sleep_Label'])\n",
    "y = df['Sleep_Label']\n",
    "\n",
    "# Train/Test Segmentation and Scaling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Defining an Evaluation Function\n",
    "results = []\n",
    "\n",
    "def evaluate_test(model, model_name, stage):\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    results.append({\n",
    "        'KFold': 'Test',\n",
    "        'Model': model_name,\n",
    "        'Stage': stage,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'MSE': mean_squared_error(y_test, y_proba),\n",
    "        'R²': r2_score(y_test, y_proba)\n",
    "    })\n",
    "\n",
    "def evaluate_cv(model, model_name, n_fold):\n",
    "    skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "    y_proba = cross_val_predict(model, X_train_scaled, y_train, cv=skf, method=\"predict_proba\")[:, 1]\n",
    "    y_pred = (y_proba >= 0.5).astype(int)\n",
    "    results.append({\n",
    "        'KFold': f\"{n_fold}-Fold\",\n",
    "        'Model': model_name,\n",
    "        'Stage': 'CV',\n",
    "        'Accuracy': accuracy_score(y_train, y_pred),\n",
    "        'MSE': mean_squared_error(y_train, y_proba),\n",
    "        'R²': r2_score(y_train, y_proba)\n",
    "    })\n",
    "\n",
    "# Evaluation of the base model\n",
    "models = [\n",
    "    (\"Logistic Regression\", LogisticRegression(max_iter=1000, random_state=42)),\n",
    "    (\"Decision Tree\", DecisionTreeClassifier(random_state=42)),\n",
    "    (\"Random Forest\", RandomForestClassifier(random_state=42))\n",
    "]\n",
    "\n",
    "for name, model in models:\n",
    "    evaluate_test(model, name, \"Test\")\n",
    "    for k in [3, 5, 10]:\n",
    "        evaluate_cv(model, name, k)\n",
    "\n",
    "# Setting parameters for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'max_depth': [5, 10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# 7. Tuning(RandomForestClassifier) for k=3,5,10\n",
    "for k in [3, 5, 10]:\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    # GridSearchCV\n",
    "    grid = GridSearchCV(\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        param_grid,\n",
    "        cv=skf,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(X_train_scaled, y_train)\n",
    "    best_grid = grid.best_estimator_\n",
    "    evaluate_test(best_grid, f\"Random Forest (GridSearch, {k}-Fold)\", \"Test\")\n",
    "    evaluate_cv(best_grid, f\"Random Forest (GridSearch, {k}-Fold)\", k)\n",
    "\n",
    "    # RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=20,\n",
    "        cv=skf,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    random_search.fit(X_train_scaled, y_train)\n",
    "    best_random = random_search.best_estimator_\n",
    "    evaluate_test(best_random, f\"Random Forest (RandomSearch, {k}-Fold)\", \"Test\")\n",
    "    evaluate_cv(best_random, f\"Random Forest (RandomSearch, {k}-Fold)\", k)\n",
    "\n",
    "# Output Results\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb3f7dd",
   "metadata": {
    "papermill": {
     "duration": 0.002074,
     "end_time": "2025-06-02T06:36:16.611594",
     "exception": false,
     "start_time": "2025-06-02T06:36:16.609520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Choose from Si-Random Forest for Acuity, MSE, and R²\n",
    "- After tuning, K-Fold [3, 5, 10] evaluation (consider test and CV difference, Accuracy, MSE, R², etc.)\n",
    "- best combination : Random Forest (RandomSearch, 5-Fold)\n",
    "- Next Top 4 (k=3,5,10)\n",
    "- Random Forest (GridSearch, 10-Fold)\n",
    "- Random Forest (RandomSearch, 10-Fold)\n",
    "- Random Forest (GridSearch, 3-Fold)\n",
    "- Random Forest (GridSearch, 5-Fold)\n",
    "- You can definitely see that the performance increases when you do the tuning. It takes too long to season, so proceed separately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9e93b8",
   "metadata": {
    "papermill": {
     "duration": 0.002054,
     "end_time": "2025-06-02T06:36:16.615918",
     "exception": false,
     "start_time": "2025-06-02T06:36:16.613864",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Regression\n",
    "- Model: Linear, RandomForest, GradientBoosting\n",
    "- Rating: R², MSE (KFold)\n",
    "- Choose the best model among the three models and tune it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc10b770",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T06:36:16.622861Z",
     "iopub.status.busy": "2025-06-02T06:36:16.622530Z",
     "iopub.status.idle": "2025-06-02T06:36:54.659048Z",
     "shell.execute_reply": "2025-06-02T06:36:54.657846Z"
    },
    "papermill": {
     "duration": 38.044092,
     "end_time": "2025-06-02T06:36:54.662782",
     "exception": false,
     "start_time": "2025-06-02T06:36:16.618690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      KFold                                  Model Stage       MSE        R²\n",
      "0      Test                      Linear Regression  Test  0.004038  0.787850\n",
      "1    3-Fold                      Linear Regression    CV  0.003887  0.780148\n",
      "2    5-Fold                      Linear Regression    CV  0.003823  0.783786\n",
      "3   10-Fold                      Linear Regression    CV  0.003843  0.782666\n",
      "4      Test                Random Forest Regressor  Test  0.002387  0.874627\n",
      "5    3-Fold                Random Forest Regressor    CV  0.002827  0.840089\n",
      "6    5-Fold                Random Forest Regressor    CV  0.002888  0.836644\n",
      "7   10-Fold                Random Forest Regressor    CV  0.002869  0.837748\n",
      "8      Test            Gradient Boosting Regressor  Test  0.002248  0.881899\n",
      "9    3-Fold            Gradient Boosting Regressor    CV  0.002921  0.834805\n",
      "10   5-Fold            Gradient Boosting Regressor    CV  0.002874  0.837451\n",
      "11  10-Fold            Gradient Boosting Regressor    CV  0.002759  0.843974\n",
      "12     Test     Random Forest (GridSearch, 3-Fold)  Test  0.002211  0.883838\n",
      "13   3-Fold     Random Forest (GridSearch, 3-Fold)    CV  0.002729  0.845643\n",
      "14     Test   Random Forest (RandomSearch, 3-Fold)  Test  0.002173  0.885843\n",
      "15   3-Fold   Random Forest (RandomSearch, 3-Fold)    CV  0.002725  0.845870\n",
      "16     Test     Random Forest (GridSearch, 5-Fold)  Test  0.002192  0.884845\n",
      "17   5-Fold     Random Forest (GridSearch, 5-Fold)    CV  0.002630  0.851269\n",
      "18     Test   Random Forest (RandomSearch, 5-Fold)  Test  0.002173  0.885843\n",
      "19   5-Fold   Random Forest (RandomSearch, 5-Fold)    CV  0.002628  0.851349\n",
      "20     Test    Random Forest (GridSearch, 10-Fold)  Test  0.002192  0.884845\n",
      "21  10-Fold    Random Forest (GridSearch, 10-Fold)    CV  0.002668  0.849090\n",
      "22     Test  Random Forest (RandomSearch, 10-Fold)  Test  0.002173  0.885843\n",
      "23  10-Fold  Random Forest (RandomSearch, 10-Fold)    CV  0.002655  0.849843\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import randint\n",
    "\n",
    "# data loading\n",
    "df = pd.read_csv(\"/kaggle/input/sleep-efficiency/ModelingSet.csv\")\n",
    "X = df.drop(columns=['Sleep efficiency'])\n",
    "y = df['Sleep efficiency']\n",
    "\n",
    "# Train/Test Segmentation and Scaling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Defining an Evaluation Function\n",
    "results = []\n",
    "\n",
    "def evaluate_test_reg(model, model_name, stage, kfold_desc):\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    results.append({\n",
    "        'KFold': kfold_desc,\n",
    "        'Model': model_name,\n",
    "        'Stage': stage,\n",
    "        'MSE': mse,\n",
    "        'R²': r2\n",
    "    })\n",
    "\n",
    "def evaluate_cv_reg(model, model_name, kf, kfold_desc):\n",
    "    y_pred_cv = cross_val_predict(model, X_train_scaled, y_train, cv=kf)\n",
    "    mse = mean_squared_error(y_train, y_pred_cv)\n",
    "    r2 = r2_score(y_train, y_pred_cv)\n",
    "    results.append({\n",
    "        'KFold': kfold_desc,\n",
    "        'Model': model_name,\n",
    "        'Stage': 'CV',\n",
    "        'MSE': mse,\n",
    "        'R²': r2\n",
    "    })\n",
    "\n",
    "# Evaluation of the base model\n",
    "models = [\n",
    "    (\"Linear Regression\", LinearRegression()),\n",
    "    (\"Random Forest Regressor\", RandomForestRegressor(random_state=42)),\n",
    "    (\"Gradient Boosting Regressor\", GradientBoostingRegressor(random_state=42))\n",
    "]\n",
    "\n",
    "for name, model in models:\n",
    "    evaluate_test_reg(model, name, \"Test\", \"Test\")\n",
    "    for k in [3, 5, 10]:\n",
    "        kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "        evaluate_cv_reg(model, name, kf, f\"{k}-Fold\")\n",
    "\n",
    "# Parameters to be tuned\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'max_depth': [5, 10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Tuning - GridSearch & RandomSearch for k in 3,5,10\n",
    "for k in [3, 5, 10]:\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    # GridSearchCV\n",
    "    grid = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=kf, n_jobs=-1)\n",
    "    grid.fit(X_train_scaled, y_train)\n",
    "    best_rf_grid = grid.best_estimator_\n",
    "    evaluate_test_reg(best_rf_grid, f\"Random Forest (GridSearch, {k}-Fold)\", \"Test\", \"Test\")\n",
    "    evaluate_cv_reg(best_rf_grid, f\"Random Forest (GridSearch, {k}-Fold)\", kf, f\"{k}-Fold\")\n",
    "\n",
    "    # RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(\n",
    "        RandomForestRegressor(random_state=42),\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=20,\n",
    "        cv=kf,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    random_search.fit(X_train_scaled, y_train)\n",
    "    best_rf_random = random_search.best_estimator_\n",
    "    evaluate_test_reg(best_rf_random, f\"Random Forest (RandomSearch, {k}-Fold)\", \"Test\", \"Test\")\n",
    "    evaluate_cv_reg(best_rf_random, f\"Random Forest (RandomSearch, {k}-Fold)\", kf, f\"{k}-Fold\")\n",
    "\n",
    "# Output Results\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1623076",
   "metadata": {
    "papermill": {
     "duration": 0.002243,
     "end_time": "2025-06-02T06:36:54.669323",
     "exception": false,
     "start_time": "2025-06-02T06:36:54.667080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- Random Forest is comparable to the predictive performance of Random Foreset Regressor, Gradient Boosting Regressor,\n",
    "Random forest with a smaller drop difference when K-folded\n",
    "- After tuning, K-Fold [3, 5, 10] evaluation (consideration of test and CV difference, MSE, R², etc.)\n",
    "- best combination : Random Forest (RandomSearch, 5-Fold)\n",
    "- Next Top 4 (k=3,5,10)\n",
    "- Random Forest (GridSearch, 5-Fold)\n",
    "- Random Forest (RandomSearch, 10-Fold)\n",
    "- Random Forest (RandomSearch, 3-Fold)\n",
    "- Random Forest (GridSearch, 10-Fold)\n",
    "- Certainly, you can see that the performance increases when you proceed with tuning."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7568391,
     "sourceId": 12028971,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 86.674346,
   "end_time": "2025-06-02T06:36:57.292643",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-02T06:35:30.618297",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
